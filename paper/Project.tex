\documentclass{article}
\usepackage{hyperref}
\usepackage{listings}

\usepackage{caption}
\captionsetup[lstlisting]{font={small,tt}}

\usepackage{fancyvrb}

\author{
	Dub\'e, Fletcher\\
	\texttt{\#921441405}
	\and
	Redivo, Leonardo\\
	\texttt{\#918072175}
	\and
	Voragen, Richard\\
	\texttt{\#917981018}
}
\title{Parallel Mandelbrot: \\An exercise in CUDA and OpenMP}

\begin{document}
\maketitle

\section{Introduction} \label{sec:intro}
    The \emph{Mandelbrot set} is the set of complex numbers $c$ for which the function
    \begin{equation} \label{eq:mandelbrot}
    f_c(z) = z^2 + c
    \end{equation}
    does not diverge to infinity when iterated from $z = 0$ \cite{mandel_wiki}. In simple terms: choose a complex number $c$, and let $z = 0$. Compute the result, and let $z$ be that result. Continue iterating until the function results in a value that exceeds some threshold, or until some large number of iterations have been computed. If the function exceeds the threshold, the function diverges and $c$ is \emph{not} in the set. Otherwise, the function does not diverge and $c$ is included in the set.

\section{Parallel Design}
    To render the Mandelbrot set on the complex plane, each complex number is represented by a pixel. A pixel is colored black if it is in the Mandelbrot set. Otherwise, it is given a color based on how many iterations before the value of the function exceeded the threshold. Given that each pixel can be colored independent of other pixels, the problem is embarassingly parallel.

    \subsection{Partitioning}
        The essential task in this problem is to color a single pixel as described above. Therefore, the color of many different pixels is computed in parallel.

    \subsection{Communication}
        The primitive tasks are completely independent of each other, so the tasks need not communicate with each other. However, the result (pixel color) of each task must be delivered to some combined data structure that represents the color of each point on the plane.

    \subsection{Agglomeration}
        Each primitive task requires no information except the complex number it represents. Additionally, the only work done is to repeatedly apply function \ref{eq:mandelbrot}. Therefore, it is not appropriate to agglomerate any tasks.

    \subsection{Mapping}
        The problem is to be broken up by sets of pixels: each worker takes some set of pixels to color.


\section{Implementation} \label{sec:impl}
    The base source code was taken from Macalester College \cite{mandel_orig}, which included a basic CUDA implementation and simple X11 display, as well as a benchmarking utility.

    \subsection{Serial}
        As a baseline, a serial version of the Mandelbrot algorithm was implemented (Appendix \ref{appendix:serial}.) This version has a number of improvements over a na\"ive implementation.
        %% richard finish this paragraph

    \subsection{OpenMP}
        To compute Mandelbrot on multiple CPU threads, the OpenMP \verb|parallel for| pragma is used (Appendix \ref{appendix:omp}.) The \verb|schedule(runtime)| clause allows the scheduling strategy to be set by changing the command-line environment variable \verb|OMP_SCHEDULE|. The \verb|dynamic| schedule was hypothesized to be optimal, because some blocks of pixels are easier to compute than others, because they converge faster. In testing, the \verb|guided| strategy resulted in the most speedup. This was a surprising result; there is not an obvious ``reverse taper'' of work to be done per complex number (later computations shouldn't necessarily be much more taxing than earlier ones.)

    \subsection{CUDA}
        The CUDA implementation (Appendix \ref{appendix:cuda}) determines the number of pixels for each thread, and each thread computes the color of each pixel assigned to it. These computed values are stored in a shared memory array \verb|colors[]|, which is then copied to host memory after the threads finish.

\section{Experimentation}
    The primary focus of experimentation was to examine the effect of different CUDA thread configurations on speedup. Specifically, the number of blocks $b$ and the number of threads per block $t$ were varied. In order to facilitate fair comparison, these values are varied such that the total number of threads $t \times b$ remained constant. It's worth noting that any optimal values may vary among GPUs.

    In each case, one-hundred $1\,600 \times 1\,600$ instances were run. The total number of threads was limited to 524\,288 because device memory is allocated for each thread. The raw output from test runs is in Appendix \ref{appendix:testdata}.

    \def\boxit#1{%
      \smash{\fboxsep=0pt\llap{\rlap{\fbox{\strut\makebox[#1]{}}}~}}\ignorespaces
    }

    \renewcommand{\arraystretch}{1.5}
    \begin{table}[h]
    \centering
    \caption{Speedup based on thread configuration}
    \begin{tabular}{r | r || r}\label{tab:speedup}
    \# of blocks & threads/block & speedup \\ \hline
    512                 & 1\,024    & 17.99 \\
    1\,024              & 512       & 18.24 \\
    \boxit{150pt}2\,048 & 256       & 18.35 \\
    4\,096              & 128       & 18.13 \\
    8\,192              & 64        & 18.16 \\
    16\,384             & 32        & 18.15
    \end{tabular}
    \end{table}

    The results in Table \ref{tab:speedup} suggest that a balance between the number of blocks and the number of threads per block is optimal. Specifically, using 2\,048 blocks and 256 threads per block yielded a 18.35x speedup over the serial version. Any improvement is fairly minimal, with a $\sim 2\%$ difference between the fastest and the slowest thread configurations; though, running higher-resolution instances (more work) would amplifiy any minor speedup differences. The program was run on an NVIDIA 1050; it's worth noting that in limited testing on less capable hardware the effect was more pronounced.

    \subsection{nvvp}
    %todo Leo

\pagebreak    
\appendix
    \section{Contributions}
        \begin{itemize}
        	\item \emph{Fletcher}: \LaTeX{}; CUDA optimization and testing; PowerPoint.

        	\item \emph{Leonardo}: CUDA optimization and testing; PowerPoint; \LaTeX{}.

        	\item \emph{Richard}: UX (X11, zoom and pan), serial, and OpenMP in \ref{appendix:mandelbrot.cu}; assisted in optimization testing and data collection; \LaTeX{}; PowerPoint.
        \end{itemize}

    \section{Gallery}


    \section{Code}
        \lstset{language=C,stringstyle=\ttfamily, showstringspaces=false, numbers=left, frame=single, framexrightmargin=0pt, columns=fullflexible, breaklines=true, breakatwhitespace=true}

        \subsection{Serial Mandelbrot}\label{appendix:serial}
\begin{lstlisting}
uint32_t mandel_double_single(double cr, double ci, int max_iter) {
    double zr = 0, zi = 0, zrsqr = 0, zisqr = 0;

    uint32_t i;

    for (i = 0; i < max_iter; i++){
		zi = zr * zi;
		zi += zi;
		zi += ci;
		zr = zrsqr - zisqr + cr;
		zrsqr = zr * zr;
		zisqr = zi * zi;
		
    //the fewer iterations it takes to diverge, the farther from the set
		if (zrsqr + zisqr > 4.0) break;
    }
    return i;
}
\end{lstlisting}

        \subsection{OpenMP Mandelbrot}\label{appendix:omp}
\begin{lstlisting}
void mandel_single(uint32_t *counts, double xmin, double ymin,
            double step, int max_iter, int dim, uint32_t *colors) {
    int i, x, y;
    double cr, ci;
    if (Version == 1){
        # pragma omp parallel for num_threads(CPU_CORES) \
            schedule(runtime) private(i,x,y,cr,ci) \
            shared(counts, dim, colors, xmin, ymin, step, max_iter)
        for (i = 1; i < dim*dim; i++){
            x = i % dim;
            y = i / dim;
            cr = xmin + x * step;
            ci = ymin + y * step;
            counts[y * dim + x]  = colors[mandel_double_single(cr, ci, max_iter)];
        }
    } else {
        for (i = 1; i < dim*dim; i++){
            x = i % dim;
            y = i / dim;
            cr = xmin + x * step;
            ci = ymin + y * step;
            counts[y * dim + x]  = colors[mandel_double_single(cr, ci, max_iter)];
        }
    }
}
\end{lstlisting}

        \subsection{CUDA Mandelbrot}\label{appendix:cuda}
\begin{lstlisting}
__global__ void mandel_kernel(uint32_t *counts, double xmin, double ymin,
            double step, int max_iter, int dim, uint32_t *colors) {
    int pix_per_thread = dim * dim / (gridDim.x * blockDim.x);
    int tId = blockDim.x * blockIdx.x + threadIdx.x;
    int offset = pix_per_thread * tId;
    for (int i = offset; i < offset + pix_per_thread; i++){
        int x = i % dim;
        int y = i / dim;
        double cr = xmin + x * step;
        double ci = ymin + y * step;
        counts[y * dim + x]  = colors[mandel_double(cr, ci, max_iter)];
    }
    if (gridDim.x * blockDim.x * pix_per_thread < dim * dim
            && tId < (dim * dim) - (blockDim.x * gridDim.x)){
        int i = blockDim.x * gridDim.x * pix_per_thread + tId;
        int x = i % dim;
        int y = i / dim;
        double cr = xmin + x * step;
        double ci = ymin + y * step;
        counts[y * dim + x]  = colors[mandel_double(cr, ci, max_iter)];
    }
}
\end{lstlisting}

        \subsection{Entire Program} \label{appendix:mandelbrot.cu}
            \lstinputlisting[caption={mandelbrot.cu}]{../mandelbrot.cu}

    \section{Test runs} \label{appendix:testdata}
        \lstset{language={},numbers=none}
        \lstinputlisting{output.txt}

\bibliography{biblio} 
\bibliographystyle{ieeetr}

\end{document}